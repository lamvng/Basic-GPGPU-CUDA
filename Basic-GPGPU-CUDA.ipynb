{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic-GPGPU-CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieo0fivLm659"
      },
      "source": [
        "# **Basic CUDA GPU Programming**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kTLlbfGW88i"
      },
      "source": [
        "# Basic-GPGPU-CUDA\n",
        "\n",
        "This is a step-by-step guide for beginners towards GPGPU structure and CUDA programming. Along with my own explanation, I also references some great documents and tutorials so you can discover yourself.\n",
        "\n",
        "Some concepts are mentioned and explained in this tutorial, including:\n",
        "\n",
        "* Basic CUDA structure;\n",
        "* Thread indexing;\n",
        "* Thread hierarchy;\n",
        "* Shared memory and conflict management;\n",
        "* Block reduction;\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "> Basic understanding of C/C++ is enough to start the tutorial.\n",
        "\n",
        "### Personal notes:\n",
        ">>\n",
        "The course (in French only) is found [here](https://p-fb.net/master-1/gpgpu.html) by Dr. Pierre-Fran√ßois Bonnefoi. On a personal side, I admired his effort and passion to deliver huge course contents and detailed instruction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFYlIO9TMZT"
      },
      "source": [
        "Some useful links here. It's ok if one cannot understand them right away, but they will be useful later in the course. \n",
        "\n",
        "* [CUDA C/C++ Basic](https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf) from NVIDIA Coproration;\n",
        "* [Optimizing Parallel Reduction](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf) from NVIDIA Corporation;\n",
        "* [CUDA Thread Indexing Cheat Sheet](https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf) from Calvin University;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGL_cY_qwrp"
      },
      "source": [
        "# **CUDA Installation**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrQPmxeIBvth"
      },
      "source": [
        "CUDA installation may vary a bit depends on your OS and distribution. Nvidia has provided detailed instruction on both Windows and Linux environment, which can be found here:\n",
        "\n",
        "* Linux: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
        "* Windows: https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfUtFbRovnMm"
      },
      "source": [
        "<u>**For those who do not possess a CUDA-capable GPU**</u>, you can make use of free GPU provided by [Google Colaboratory](https://colab.research.google.com/notebooks/gpu.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Ub7EurPDiY"
      },
      "source": [
        "Otherwise, [this guide](https://harshityadav95.medium.com/how-to-run-cuda-c-or-c-on-google-colab-or-azure-notebook-ea75a23a5962) shows the necessary steps to run CUDA directly on Google Colab, which is shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDwrN7yn_XKB"
      },
      "source": [
        "Firstly, change the environment type to `GPU` (mentioned in the [link](https://harshityadav95.medium.com/how-to-run-cuda-c-or-c-on-google-colab-or-azure-notebook-ea75a23a5962) above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFZm_3kPJq6"
      },
      "source": [
        "Set up the libraries (run only once to initiate the environment):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcZiqE2sq0jR"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n",
        "\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "%!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4wTAwC8IUEo"
      },
      "source": [
        ">**On each session**, install [this extension](https://github.com/\n",
        "andreinechaev/nvcc4jupyter) to allow CUDA compilation on Jupyter Notebook:\n",
        "\n",
        "> Every cell with CUDA code must be initialized by `%%cu`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xe3773rIRoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6618e4ae-fae9-4472-c293-31ffafa3ce46"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-hkznr_ud\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-hkznr_ud\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=c23a78410f24437b192b47c3469bacad2d8f001a98a09c0739557a978a7baaa3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0v7ru7to/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxSlkw9Qq9a0"
      },
      "source": [
        "# **First Program**\n",
        "---\n",
        "\n",
        "There are two components participating in a CUDA program:\n",
        "\n",
        "* **Host**: The CPU and its memory\n",
        "* **Device**: The GPU and its memory\n",
        "\n",
        "Therefore, a CUDA program consists of two parts: One part executes in GPU (parallel computing) and the other in CPU.\n",
        "\n",
        "> We usually use prefix before each device funtion to indicate its scope. For example, `__global__` prefix means that the function executes on device (GPU), and can be called from the host (CPU).\n",
        "\n",
        "Read more on [CUDA C/C++ Basics](https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf).\n",
        "\n",
        "The example below illustrate how to perform `a+b` (`a`and `b` are integers) on GPU.\n",
        "\n",
        "* Supposing `c = a + b`. We must allocate host and device variables separately. The way we allocate memory is similar to a pointer.\n",
        "* The values are initiated on CPU, then **copied** to GPU for calculation. Results are returned back to CPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXTilEIsXGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711b715c-e51f-4a70-ccdc-b0fea7bb0119"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "// __global__ prefix \n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "int main (void) {\n",
        "    int a, b, c; //host variables\n",
        "    int *d_a, *d_b, *d_c; //device variables\n",
        "    int size = sizeof(int);\n",
        "\n",
        "    // Memory allocation for device variables\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Setup initial values\n",
        "    a = 2;\n",
        "    b = 7;\n",
        "\n",
        "    // Copy input to device\n",
        "    cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch add() kernel on GPU\n",
        "    add<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copy results to host\n",
        "    cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    printf(\"Result: %d + %d = %d\", a, b, c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: 2 + 7 = 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmM7XT4nZZQC"
      },
      "source": [
        "# **Threads, blocks, and grids**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_cBCcd-nTMy"
      },
      "source": [
        "Useful links:\n",
        "* **CUDA Basic**: https://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf\n",
        "\n",
        "* **Kernels, Grids, Threads, Blocks**: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy-yhGnrcOmJ"
      },
      "source": [
        "## ***Exercise 1: Vector addition***\n",
        "> Look at the program below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMTwYVuTckiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431a9540-7035-4197-cb99-ad77a7ab7556"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10\n",
        "\n",
        "#include<stdio.h>\n",
        "static void HandleError (cudaError_t err, const char *file, int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"%s in %s at line %d\\n\", cudaGetErrorString(err), file, line);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "#define HANDLE_ERROR(err) (HandleError(err, __FILE__, __LINE__))\n",
        "// HANDLE_ERROR(my_instruction_cuda_here());\n",
        "\n",
        "\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    int tid = blockIdx.x;\n",
        "    if (tid < N)\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "\n",
        "int main (void) {\n",
        "    int a[N], b[N], c[N]; // Host variables\n",
        "    int *dev_a, *dev_b, *dev_c; // Device variables\n",
        "\n",
        "    // Memory allocation on Device\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(int));\n",
        "\n",
        "    // Fill \"a\" and \"b\" array on CPU\n",
        "    for(int i=0; i<N; i++) {\n",
        "        a[i] = -i;\n",
        "        b[i] = i * i;\n",
        "    }\n",
        "\n",
        "    // Copy \"a\" and \"b\" array to GPU\n",
        "    int size = N * sizeof(int);\n",
        "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Operations on GPU\n",
        "    add<<<N,1>>>(dev_a, dev_b, dev_c); // Launch add() kernel on GPU with N blocks\n",
        "\n",
        "    // Copy results back to host\n",
        "    HANDLE_ERROR(cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "\n",
        "    printf(\"Array a: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", a[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Array b: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", b[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Array c: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", c[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array a:    0  -1  -2  -3  -4  -5  -6  -7  -8  -9\n",
            "Array b:    0   1   4   9  16  25  36  49  64  81\n",
            "Array c:    0   0   2   6  12  20  30  42  56  72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awfayN1LkEPM"
      },
      "source": [
        "### a. Explain the purpose of `blockIdx.x` notation in kernel function `add()`\n",
        "\n",
        "* `blockIdx.x` is used to index the array in the GPU, each block handles a different element of the array in parallel.\n",
        "\n",
        "  * By using `blockIdx.x` to index into the array, each block handles a different element of the array, the input data are separated into multiple blocks.\n",
        "  * On the device, each block can execute in parallel, for example:\n",
        "      * Block 0: `c[0] = a[0] + b[0]`\n",
        "      * Block 1: `c[1] = a[1] + b[1]`\n",
        "      * Block 2: `c[2] = a[2] + b[2]`\n",
        "\n",
        "#### b. In kernel function, why `if (tid < N)` is needed ?\n",
        "  * Explanation on kernel call `add<<<N,1>>>(dev_a, dev_b, dev_c);` (line 45) from host: The host calls for `N` blocks for the `N` elements in each array (`a` `b` `c`, each has `N` elements). It makes sure that the number of blocks is not greater than the total elements of each array.\n",
        "    * If the number of blocks **is not equal to** array length:\n",
        "      * `Blocks` < `arrays`: Eg. Blocks = 5, just 5 elements of `c` is calculated, the rest is `0`.\n",
        "```\n",
        "Array a: 0 -1 -2 -3 -4 -5 -6 -7 -8 -9 \n",
        "Array b: 0  1  4  9  16  25  36  49  64  81  \n",
        "Array c: 0  0  2  6  12  0  0  0  0  0\n",
        "```\n",
        "\n",
        "      * `Blocks` > `arrays`: Just 10 blocks are used, the rest are unused.\n",
        "```\n",
        "Array a: 0 -1 -2 -3 -4 -5 -6 -7 -8 -9 \n",
        "Array b: 0  1  4  9  16  25  36  49  64  81  \n",
        "Array c: 0  0  2  6  12  20  30  42  56  72\n",
        "```\n",
        "    * It is possible that the number of blocks is smaller than array length. In that case, **threads** must be invoked *\\_\\_global\\_\\_* function, which is mentioned below.\n",
        "\n",
        "\n",
        "\n",
        "#### c. Describe the program using blocks, threads, and grids notation\n",
        "\n",
        "Based on the kernel call `add<<<N,1>>>(dev_a, dev_b, dev_c)`:\n",
        "\n",
        "  * When a kernel is called, the device memory will be allocated a grid **(each kernel call corresponds to a grid)** The input array is divided in `N` blocks, each block contains 1 thread. The addition operation is done in parallel in the blocks.\n",
        "\n",
        "  * **Thread indexing**: https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf\n",
        "  * **Thread hierachy**: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i3UUz6vxxOl"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0KZafynBpps"
      },
      "source": [
        "### **Summary**:\n",
        "\n",
        "  * Host: CPU (host), controlling the device.\n",
        "  * GPU: The device which performs calculation in parallel.\n",
        "  * Kernel: A function with \\_\\_global\\_\\_ notation, performed by device upon request form host.\n",
        "    * A kernel function is done on multiple threads in parallel.\n",
        "  * **Grid** --> **Block** --> **Thread**\n",
        "    * **Grid**: Each kernel call comes with a allocation of a grid.\n",
        "    * **Block**: There are many blocks in a grid.\n",
        "    * **Thread**: There are many threads in a block.\n",
        "\n",
        "**Thread indexing**:\n",
        "\n",
        "`tid = blockIdx.x * blockDim.x + threadIdx.x`\n",
        "\n",
        "  * `blockId.x:`: Index of a block in a grid.\n",
        "  * `blockDim.x`: The number of threads in a block.\n",
        "  * `threadIdx.x`: Index of a thread **in a block**.\n",
        "  * `tid`: Index of thread inside a grid. This is unique in a grid.\n",
        "\n",
        "### **Kernel call:**\n",
        "  * `add<<<number_of_blocks, number_of_threads>>>`\n",
        "    * `add<<<1, N>>>`: One block with several threads\n",
        "    * `add<<<N, 1>>>`: Several blocks with one thread each\n",
        "    * `add<<<M, N>>>`: `M` blocks, each block contains `N` threads\n",
        "\n",
        "### **Combining Threads and Blocks**\n",
        "  * Each block within the grid can be identified by a one-dimensional, two-dimensional, or three-dimensional unique index accessible within the kernel through `blockIdx` variable.\n",
        "    * Eg: **dim3 threadsPerBlock(16, 16);** : Number of threads per block\n",
        "      * The number of threads per block and the number of blocks per grid specified in the `<<<...>>>` syntax can be of type `int` or `dim3`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UIqSFuPcs6E"
      },
      "source": [
        "#### d. What will happen if we change the kernel call to `add<<<1,N>>>( dev_a, dev_b, dev_c );`\n",
        "\n",
        "* `add<<<1,N>>>( dev_a, dev_b, dev_c );` means that the function executes on only 1 block which contains `N` threads running in parallel.\n",
        "\n",
        "* Therefore we have to modify the device function `add()`. Change the `tid` variable to `tid = threadIdx.x` instead of `blockIdx.x`.\n",
        "\n",
        "```\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid < N)\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "```\n",
        "\n",
        "  * There is a limit to the number of threads per block, since all threads of a block are expected to reside on the same processor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads. Read more [here](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZCWWjOXL6Ty",
        "outputId": "781b9e21-2c97-4e07-887a-a4df01ccf6f3"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10\n",
        "\n",
        "#include<stdio.h>\n",
        "static void HandleError (cudaError_t err, const char *file, int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"%s in %s at line %d\\n\", cudaGetErrorString(err), file, line);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR(err) (HandleError(err, __FILE__, __LINE__))\n",
        "// HANDLE_ERROR(my_instruction_cuda_here());\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid < N)\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "\n",
        "int main (void) {\n",
        "    int a[N], b[N], c[N]; // Host variables\n",
        "    int *dev_a, *dev_b, *dev_c; // Device variables\n",
        "\n",
        "    // Memory allocation on Device\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(int));\n",
        "\n",
        "    // Fill \"a\" and \"b\" array on CPU\n",
        "    for(int i=0; i<N; i++) {\n",
        "        a[i] = -i;\n",
        "        b[i] = i * i;\n",
        "    }\n",
        "\n",
        "    // Copy \"a\" and \"b\" array to GPU\n",
        "    int size = N * sizeof(int);\n",
        "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Operations on GPU\n",
        "    add<<<1,N>>>(dev_a, dev_b, dev_c); // Launch add() kernel on GPU with N blocks\n",
        "\n",
        "    // Copy results back to host\n",
        "    HANDLE_ERROR(cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c);\n",
        "\n",
        "    printf(\"Array a: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", a[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Array b: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", b[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Array c: \");\n",
        "    for (int i=0; i<N; i++) {\n",
        "        printf(\"%4d\", c[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array a:    0  -1  -2  -3  -4  -5  -6  -7  -8  -9\n",
            "Array b:    0   1   4   9  16  25  36  49  64  81\n",
            "Array c:    0   0   2   6  12  20  30  42  56  72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE_1hfdRIazp"
      },
      "source": [
        "## ***Exercise 2: Dealing with large array size***\n",
        "\n",
        "How to deal with a large array which surpass the maximum number of threads in our GPU?\n",
        "\n",
        "1.   √âl√©ment de liste\n",
        "2.   √âl√©ment de liste\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unHYkCgMhPc0"
      },
      "source": [
        "#### a. What should we do if the vector size is more than the maximum threads possible in a block (for example `N = 65536` ?\n",
        "  * We can use multiple blocks in parallel if the vector size is more than `1024`.\n",
        "  * Another solution is also possible: Divide the job (`N` vector elements) to our availabe threads (`1024`), therefore each thread will perform several integer addition (in series of course).\n",
        "\n",
        "In this exercise, the first proposition will be applied.\n",
        "\n",
        "#### b. How is the number of blocks calculated?\n",
        "\n",
        "```\n",
        "nb_threads = 128;\n",
        "nb_blocks = (N + nb_threads - 1) / nb_threads;\n",
        "add <<< nb_blocks, nb_threads >>> (dev_a, dev_b, dev_c);\n",
        "```\n",
        "\n",
        "* Supposing each block contains 128 threads;\n",
        "* The number of allocated blocks: `nb_blocks = (N + nb_threads - 1) / nb_threads;`\n",
        "\n",
        "\n",
        "#### c. Explain how `tid` is calculated below?\n",
        "\n",
        "\n",
        "`int tid = threadIdx.x + blockIdx.x * blockDim.x;`\n",
        "  * In this example, the vector is only one-dimensional (dimension `x`).\n",
        "    * `threadIdx.x` : Index of the thread **in a block** in dimension `x`.\n",
        "    * `blockIdx.x` : Index of the block **in the grid** in dimension `x`.\n",
        "    * `blockDim.x` : Number of threads in a block in dimension `x`.\n",
        "\n",
        "<u>**Note:**</u> Therefore `blockDim.x * gridDim.x` is the total number of threads in the grid.\n",
        "\n",
        "Read more about [CUDA GridDim and BlockDim](https://stackoverflow.com/questions/16619274/cuda-griddim-and-blockdim)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oz3V8EsPt9j"
      },
      "source": [
        "> **Now read the program below:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwga3p8fkic8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d362329d-6d93-4947-9327-5b69a7f34f4f"
      },
      "source": [
        "%%cu\n",
        "#define N 32768\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void add (int *a, int *b, int *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main (void) {\n",
        "    int a[N], b[N], c[N];\n",
        "    int *dev_a, *dev_b, *dev_c;\n",
        "\n",
        "    // Allocation de memoire sur GPU\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(int));\n",
        "\n",
        "    // Creer des valeurs pour a et b sur CPU\n",
        "    for (int i=0; i<N; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = i*2;\n",
        "    }\n",
        "\n",
        "    // Copier des valeurs sur le device\n",
        "    cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Invoke Kernel\n",
        "    add<<<128, 128>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        "    // Copier tableau c sur le CPU\n",
        "    cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i=0; i<N; i++) {\n",
        "        if (i%4096 == 0)\n",
        "            printf (\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Faire libre la memoire GPU\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 0 = 0\n",
            "4096 + 8192 = 12288\n",
            "8192 + 16384 = 24576\n",
            "12288 + 24576 = 36864\n",
            "16384 + 32768 = 49152\n",
            "20480 + 40960 = 61440\n",
            "24576 + 49152 = 73728\n",
            "28672 + 57344 = 86016\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Z_XMLyqWUA"
      },
      "source": [
        "### d. What does this program do?\n",
        "Add two integer vector with size of 32768.\n",
        "\n",
        "### e. That is the purpose of line 6?\n",
        "\n",
        "`int tid = threadIdx.x + blockIdx.x * blockDim.x;`\n",
        "  * To calculate the index of thread globally (in the grid).\n",
        "\n",
        "And then on line 9 in kernel function:\n",
        "\n",
        "`tid += blockDim.x * gridDim.x;`\n",
        " \n",
        " Device call in `main()`:\n",
        "\n",
        " `add<<<128, 128>>>(dev_a, dev_b, dev_c);`\n",
        "\n",
        " * With vector size `N = 32768`, but the program execute on `128` blocks, each block contains `128` threads --> Total `128 * 128 = 16384` threads in the grid, which is less than `N`.\n",
        " * So, it is not enough space to allocate every array element in a separate cell. Therefore a single thread must perform integer addition on several array elements. But how to index the corresponding element?\n",
        "\n",
        "> Take a look at the kernel function:\n",
        "\n",
        "```\n",
        "__global__ void add (int *a, int *b, int *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "   * Operation `while (tid < N)` is to ensure the index does not greater than `N`. Si c'est le cas, `tid+=16384` pour l'iteration sur d'autre `tid` qui est `16384`.\n",
        " * For example, we have `blockDim.x * gridDim.x = 128*128 = 16384` threads in total.\n",
        "   * Thread `tid = 0` performs integer additions on cell 0 and 16384;\n",
        "   * Thread `tid = 1` performs integer additions on cell 1 and 16385;\n",
        "   * Thread `tid = 2` performs integer additions on cell 2 and 16386;\n",
        "\n",
        "... You get the idea! The job is divided between our available threads. `16384` threads still perform in parallel!\n",
        "\n",
        "\n",
        "  * Reference: https://stackoverflow.com/questions/16619274/cuda-griddim-and-blockdim\n",
        "      * In particular, when the total threads in the x-dimension (`gridDim.x*blockDim.x`) is ***less than the size of the array I wish to process***, then it's common practice to create a loop and have the grid of threads move through the entire array.\n",
        "      *  In effect, the entire grid of threads is jumping through the 1-D array of data, a grid-width at a time. This topic, sometimes called a \"grid-striding loop\", is further discussed in this [blog article](https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/).\n",
        "\n",
        "\n",
        "### f. Explain the kernel call\n",
        "`add<<<128, 128>>>(dev_a, dev_b, dev_c);`\n",
        "\n",
        "  * `N = 32768`\n",
        "  * 128 blocks, each block contains 128 threads --> Total 128 * 128 = `16384` threads.\n",
        "  * Addition operation from indices `0 --> 16383` are processed in parallelly in every thread. Then, the next indice is called by `tid += blockDim.x * gridDim.x;` if `tid < N`.\n",
        "  * Therefore, every thread works on 2 cells: thread 0 on `0, 16384`, thread 1 on `1, 16385`, thread 2 on `2, 16386`...\n",
        "  * Don't get confused! Thread `0` works on cell 0 and 16386 **in series** (firstly on cell 0, **then** cell 16386). but in the meantime, the work **between the threads** are performed in parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO-MgaM0wnIE"
      },
      "source": [
        "## ***Exercise 3: Indexing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC7NrF0kaZLH"
      },
      "source": [
        "> Look at the program below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akMYjPyWwo_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5a32be-46a4-49bb-a137-9dbc04dc18c0"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "\n",
        "static void HandleError(cudaError_t err, const char *file, int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"%s in %s at line %d\\n\", cudaGetErrorString(err), file, line);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "#define HANDLE_ERROR(err) (HandleError (err, __FILE__, __LINE__))\n",
        "#define N 500\n",
        "\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid < N) {\n",
        "        c[tid] = 2 * a[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N], b[N], c[N];\n",
        "    int *dev_a, *dev_c;\n",
        "    float time;\n",
        "    cudaEvent_t start, stop;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_a, N * sizeof(int)));\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_c, N * sizeof(int)));\n",
        "\n",
        "    // Initialize a and b on CPU\n",
        "    for (int i=0; i < N; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = 2*i;\n",
        "    }\n",
        "\n",
        "    // Copy a to GPU\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    doubler<<<1,100>>> (dev_a, dev_c);\n",
        "\n",
        "    // Checkpoint: until the device has completed all preceding requested tasks.\n",
        "    cudaThreadSynchronize(); // Returns an error if one of the preceding tasks has failed.\n",
        "\n",
        "    printf(\">%s\\n\",cudaGetErrorString (cudaGetLastError()));\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "\n",
        "    // Copy c back to CPU\n",
        "    HANDLE_ERROR(cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Show results\n",
        "    for (int i=0; i<N; i++) {\n",
        "        if ((i<=100 && i%10==0) || i%100==0)\n",
        "        printf(\"2*%d = %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "    printf(\"Execution time: %3.1f ms\\n\", time);\n",
        "\n",
        "    // Liberer espace\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">no error\n",
            "2*0 = 0 = 0\n",
            "2*10 = 20 = 20\n",
            "2*20 = 40 = 40\n",
            "2*30 = 60 = 60\n",
            "2*40 = 80 = 80\n",
            "2*50 = 100 = 100\n",
            "2*60 = 120 = 120\n",
            "2*70 = 140 = 140\n",
            "2*80 = 160 = 160\n",
            "2*90 = 180 = 180\n",
            "2*100 = 200 = 0\n",
            "2*200 = 400 = 0\n",
            "2*300 = 600 = 0\n",
            "2*400 = 800 = 0\n",
            "Execution time: 0.0 ms\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UJTHSamKJLO"
      },
      "source": [
        "  * If `N <= 100`, the program works correctly.\n",
        "  * When `N > 100`, it gives incorrect results starting from `i=100`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5DLRDbARb-0"
      },
      "source": [
        "#### What went wrong?\n",
        "Take a look at the kernel function:\n",
        "```\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid < N) {\n",
        "        c[tid] = 2 * a[tid];\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "And the kernel call:\n",
        "\n",
        "`doubler<<<1,100>>> (dev_a, dev_c);`\n",
        "\n",
        "Grid configuration: 1 block, 100 threads per block --> there is only 100 threads total in a grid, hence `tid` never surpasses `100`.\n",
        "\n",
        "Hence, only the first 100 elements of the array are calculated. There is no loop to jump to the next cells after the first 100 cells are done. \n",
        "Read more [here](ttps://stackoverflow.com/questions/16619274/cuda-griddim-and-blockdim).\n",
        "\n",
        "<u>**Fix**:</u>\n",
        "```\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = 2 * a[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "  * Change `if` to `while`;\n",
        "  * Calculate `tid += blockDim.x * gridDim.x;` to \"jump\" to the next cells, where:\n",
        "    * `gridDim.x`: Number of blocks in a grid in dimension `x`;\n",
        "    * `blockDim.x`: Number of threads in a block in dimension `x`);\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKVANd-OT5ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6540f0fb-564b-4324-92c6-061873fd8fae"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "\n",
        "static void HandleError(cudaError_t err, const char *file, int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"%s in %s at line %d\\n\", cudaGetErrorString(err), file, line);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "#define HANDLE_ERROR(err) (HandleError (err, __FILE__, __LINE__))\n",
        "#define N 500\n",
        "\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = 2 * a[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N], b[N], c[N];\n",
        "    int *dev_a, *dev_c;\n",
        "    float time;\n",
        "    cudaEvent_t start, stop;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_a, N * sizeof(int)));\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_c, N * sizeof(int)));\n",
        "\n",
        "    // Initialize a and b on CPU\n",
        "    for (int i=0; i < N; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = 2*i;\n",
        "    }\n",
        "\n",
        "    // Copy a to GPU\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    doubler<<<1,100>>> (dev_a, dev_c);\n",
        "\n",
        "    // Checkpoint: until the device has completed all preceding requested tasks.\n",
        "    cudaThreadSynchronize(); // Returns an error if one of the preceding tasks has failed.\n",
        "\n",
        "    printf(\">%s\\n\",cudaGetErrorString (cudaGetLastError()));\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "\n",
        "    // Copy c back to CPU\n",
        "    HANDLE_ERROR(cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Show results\n",
        "    for (int i=0; i<N; i++) {\n",
        "        if ((i<=100 && i%10==0) || i%100==0)\n",
        "        printf(\"2*%d = %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "    printf(\"Execution time: %3.1f ms\\n\", time);\n",
        "\n",
        "    // Liberer espace\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">no error\n",
            "2*0 = 0 = 0\n",
            "2*10 = 20 = 20\n",
            "2*20 = 40 = 40\n",
            "2*30 = 60 = 60\n",
            "2*40 = 80 = 80\n",
            "2*50 = 100 = 100\n",
            "2*60 = 120 = 120\n",
            "2*70 = 140 = 140\n",
            "2*80 = 160 = 160\n",
            "2*90 = 180 = 180\n",
            "2*100 = 200 = 200\n",
            "2*200 = 400 = 400\n",
            "2*300 = 600 = 600\n",
            "2*400 = 800 = 800\n",
            "Execution time: 0.0 ms\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F0N-kA5Wrop"
      },
      "source": [
        "## ***Exercise 4: Conflict management and synchronization***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN-smxiadMdT"
      },
      "source": [
        "### a. Modify the program to calculate `c = a*a` element-wise so it works on `N=10000`.\n",
        "\n",
        ">The kernel call should be something like `doubler<<<100,100>>()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rkiot2Q706b"
      },
      "source": [
        "This time, multiple blocks are called. Therefore, we should modify the way we calculate `tid` as follows:\n",
        "\n",
        "```\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = a[tid] * a[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiw04laUW12v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d74ab0f-dc05-4ddc-f4dc-b9594d5f7599"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "\n",
        "static void HandleError(cudaError_t err, const char *file, int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"%s in %s at line %d\\n\", cudaGetErrorString(err), file, line);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "#define HANDLE_ERROR(err) (HandleError (err, __FILE__, __LINE__))\n",
        "#define N 10000\n",
        "\n",
        "__global__ void doubler (int *a, int *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    while (tid < N) {\n",
        "        c[tid] = a[tid] * a[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N], b[N], c[N];\n",
        "    int *dev_a, *dev_c;\n",
        "    float time;\n",
        "    cudaEvent_t start, stop;\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_a, N * sizeof(int)));\n",
        "    HANDLE_ERROR (cudaMalloc ((void**)&dev_c, N * sizeof(int)));\n",
        "\n",
        "    // Initialize a and b on CPU\n",
        "    for (int i=0; i < N; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = i*i;\n",
        "    }\n",
        "\n",
        "    // Copy a to GPU\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    doubler<<<1,100>>> (dev_a, dev_c);\n",
        "\n",
        "    // Checkpoint: until the device has completed all preceding requested tasks.\n",
        "    cudaThreadSynchronize(); // Returns an error if one of the preceding tasks has failed.\n",
        "\n",
        "    printf(\">%s\\n\",cudaGetErrorString (cudaGetLastError()));\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "\n",
        "    // Copy c back to CPU\n",
        "    HANDLE_ERROR(cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Show results\n",
        "    for (int i=0; i<N; i++) {\n",
        "        if (i%1000==0)\n",
        "        printf(\"%d*%d = %d = %d\\n\", a[i], a[i], b[i], c[i]);\n",
        "    }\n",
        "    printf(\"Execution time: %3.1f ms\\n\", time);\n",
        "\n",
        "    // Liberer espace\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">no error\n",
            "0*0 = 0 = 0\n",
            "1000*1000 = 1000000 = 1000000\n",
            "2000*2000 = 4000000 = 4000000\n",
            "3000*3000 = 9000000 = 9000000\n",
            "4000*4000 = 16000000 = 16000000\n",
            "5000*5000 = 25000000 = 25000000\n",
            "6000*6000 = 36000000 = 36000000\n",
            "7000*7000 = 49000000 = 49000000\n",
            "8000*8000 = 64000000 = 64000000\n",
            "9000*9000 = 81000000 = 81000000\n",
            "Execution time: 0.1 ms\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrHOt7D0dTYm"
      },
      "source": [
        "### b. Now we want to calculate the sum of all the square `a^2`.\n",
        "\n",
        "####<center>**sum = a<sub>1</sub><sup>2</sup> + a<sub>2</sub><sup>2</sup> + ... + a<sub>N</sub><sup>2</sup>**</center>\n",
        "\n",
        "Unlike vector addition in which the job between threads are totally independent, this exercise requires cooperation and synchronization between threads.\n",
        "\n",
        "> Look at the kernel below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0i8vbsQbseB"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "\n",
        "// nb_blocks = 100;\n",
        "// nb_threads = 100;\n",
        "__global__ void square(int *a, float *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    if (tid < N) {\n",
        "        c[tid] = a[tid] * a[tid];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x == 0) {\n",
        "        float temp = 0;\n",
        "        for(int i=0; i<100; i++)\n",
        "            temp += c[tid+i];\n",
        "        c[blockIdx.x] = temp;\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oGkcT57dY6L"
      },
      "source": [
        "#### On line 9: What is `__syncthreads();` ?\n",
        "> Read more: https://stackoverflow.com/questions/15240432/does-syncthreads-synchronize-all-threads-in-the-grid\n",
        "\n",
        "* To ensure that **all threads in a block** have finished their job before advancing to the next step. (Reminder: We are in a parallel environment, each thread does not really know what happens inside one another).\n",
        "  * Note: The synchronization of `__syncthreads()` happens on **block** level.\n",
        "\n",
        "* For example, in block `0`, if thread `0` has finished calculating **sum<sub>0</sub> = a<sub>0</sub><sup>2</sup>**, but thread `1` hasn't finished their job on **sum<sub>1</sub>**, then **sum = sum<sub>0</sub> + sum<sub>1</sub>** fails to deliver expected results. There must be a *checkpoint* mechanism.\n",
        "\n",
        "#### Explain the `for` loop on line 14 and 15? How the sum is calculated?\n",
        "* Reminder: Our kernel configuration is `<<<100, 100>>>` for `N=10000`. Therefore, there are 10000 threads to handle 10000 elements. Each thread handles an element of the array.\n",
        "\n",
        "* Each thread `tid` calculates `c[tid] = a[tid] * a[tid]`.\n",
        "\n",
        "* Then, the first thread on every block (line 12) calculates the sum of block `blockIdx.x`. The result is saved on `c[blockIdx.x]`.\n",
        "  * **Improvements are needed**, since there are a lot of idle threads after `__syncthreads()` on line 12. Only the first thread on each block is active. This defeat the purpose of parallelism.\n",
        "\n",
        "* The remaining job: We need to calculate the sum of all `c[blockIdx.x]`. Generally, it is not possible to do this on the same kernel since there is no synchronization mechanism between different blocks. We can do the job on CPU, or write a different kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnIdJYeSq0mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbe1a80-eac7-4cdd-9453-ea5a7659774d"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10000\n",
        "__global__ void square(int *a, float *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    if (tid < N) {\n",
        "        c[tid] = a[tid] * a[tid];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x == 0) {\n",
        "        float temp = 0;\n",
        "        for(int i=0; i<blockDim.x; i++)\n",
        "            temp += c[tid+i];\n",
        "        c[blockIdx.x] = temp; // Save the partial sum of a block\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N];\n",
        "    int *dev_a;\n",
        "    float b, c[N];\n",
        "    float *dev_c;\n",
        "\n",
        "\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(int));\n",
        "\n",
        "    b = 0;\n",
        "    for (int i=0;i<N;i++) {\n",
        "        a[i] = i;\n",
        "        b += a[i] * a[i];\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    square<<<100,100>>>(dev_a, dev_c);\n",
        "\n",
        "    cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Faire la somme de tous les blocs dans le CPU\n",
        "    float somme = 0;\n",
        "    for (int i=0; i<100; i++) {\n",
        "        somme += c[i];\n",
        "    }\n",
        "    printf(\"Results on CPU = %1.0f\\nResults on GPU = %1.0f\", b, somme);\n",
        "\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on CPU = 333283328000\n",
            "Results on GPU = 333283328000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Yy-mLNhAjq"
      },
      "source": [
        "#### Propose an improved version of the previous kernel using shared memory\n",
        "\n",
        "* As mentioned above, the previous kernel is not optimized for parallelism.\n",
        "\n",
        "> [Shared memory](https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/) is accessible by all threads **in the same block**.\n",
        "\n",
        "* How to use shared memory properly? And to avoid conflicting read-write?\n",
        "\n",
        "Take a look at the proposed kernel below:\n",
        "\n",
        "```\n",
        "__global__ void sum(float *c, float *s) {\n",
        "    __shared__ float temp; // Declare shared varibles (block-level only)\n",
        "    int tid = threadIdx.x;\n",
        "    if (tid < 100) {\n",
        "        temp += c[tid];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    s[0] = temp;\n",
        "}\n",
        "```\n",
        "  * That one is actually not correct. In shorts, variable `temp` is accessed concurrently by several threads at the same time, which leads to [race condition](https://stackoverflow.com/questions/34510/what-is-a-race-condition). Read the first answer of [this question](https://stackoverflow.com/questions/24051820/cuda-find-sum-of-elements-of-the-array).\n",
        "\n",
        "#### **Fix**: <u>**Block reduction**</u>\n",
        "\n",
        "* This [tutorial by NVIDIA](http://developer.download.nvidia.com/compute/cuda/1.1-Beta/x86_website/projects/reduction/doc/reduction.pdf) explains in detail different ways of block reduction, along with their advantages and disadvantages.\n",
        "\n",
        "* Some more great tutorials:\n",
        " * https://www.youtube.com/watch?v=bpbit8SPMxU - Part 1\n",
        " * https://www.youtube.com/watch?v=JmnPaOXxWLg - Part 2\n",
        " * https://www.youtube.com/watch?v=iHeze1VdxYA - Part 3\n",
        " * https://www.youtube.com/watch?v=xXiA3dzl2UE - Part 4\n",
        "\n",
        "Short explaination on each method:\n",
        "\n",
        "> A noter : `sdata` c'est la m√©moire partag√©e.\n",
        "\n",
        "**1e Proposition :** Interleaved Addressing\n",
        "\n",
        "```\n",
        "__global__ void sum(float *c, float *s) {\n",
        "    __shared__ float temp[blockDim.x];\n",
        "\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    temp[threadIdx.x] = c[tid];\n",
        "    __syncthreads(); // Assurer que le tableau `temp` est remplir dans chaque block\n",
        "\n",
        "    for (int step=1; step<blockDim.x; step*=2) {\n",
        "        if (threadIdx.x % (2*step) == 0)\n",
        "            temp[threadIdx.x] += temp[threadIdx.x+step];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    \n",
        "    if (threadIdx.x == 0)\n",
        "        s[blockIdx.x] = temp[threadIdx.x] // Sauvegarder la somme d'un block\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "for(unsigned ints=1; s < blockDim.x; s *= 2) {\n",
        "    if(tid % (2*s) == 0)\n",
        "        sdata[tid] += sdata[tid + s];\n",
        "    __syncthreads();}\n",
        "```\n",
        "* Problem: Highly divergent warps are very inefficient, and % operator is very slow\n",
        "\n",
        "**2e Proposition :** Interleaved Addressing v2\n",
        "```\n",
        "for(unsigned int s=1; s < blockDim.x; s *= 2) {\n",
        "    int index = 2 * s * tid;\n",
        "    if (index < blockDim.x)\n",
        "        sdata[index] += sdata[index + s];\n",
        "    __syncthreads();}\n",
        "```\n",
        "\n",
        "* New Problem: Shared Memory Bank Conflicts\n",
        "\n",
        "**3e Proposition :** Sequential Addressing\n",
        "\n",
        "```\n",
        "for(unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
        "    if (tid < s)\n",
        "        sdata[tid] += sdata[tid + s];\n",
        "    __syncthreads();}\n",
        "```\n",
        "* Problem: Half of the threads are idle on first loop iteration! This is wasteful...\n",
        "\n",
        "**4e Proposition :**  First Add During Load\n",
        "\n",
        "```\n",
        "// perform first level of reduction\n",
        "// reading from global memory, writing to shared memory\n",
        "unsigned int tid = threadIdx.x;\n",
        "unsigned int i = blockIdx.x*(blockDim.x*2) + threadIdx.x;\n",
        "sdata[tid] = g_idata[i] + g_idata[i+blockDim.x];\n",
        "__syncthreads();\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y5VFTKS6TO_"
      },
      "source": [
        "### Implementation: Calculate the sum of an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Wo1lQo6b3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5c893c-b8f9-49a2-bc37-9005c704f044"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10240\n",
        "\n",
        "__global__ void somme(float *a, float *b) {\n",
        "    __shared__ float temp[1024];\n",
        "\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    temp[threadIdx.x] = a[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int step=1; step<blockDim.x; step*=2) {\n",
        "        if (threadIdx.x % (2*step) == 0)\n",
        "            temp[threadIdx.x] += temp[threadIdx.x+step];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0)\n",
        "        b[blockIdx.x] = temp[threadIdx.x];\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    float a[N], b[N], c[N];\n",
        "    float *dev_a, *dev_b, *dev_c;\n",
        "    float sum;\n",
        "\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(float));\n",
        "    cudaMalloc((void**)&dev_b, N * sizeof(float));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(float));\n",
        "\n",
        "    sum = 0;\n",
        "    for (int i=0;i<N;i++) {\n",
        "        a[i] = 1;\n",
        "        sum += a[i];\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int block_size = 1024;\n",
        "    int grid_size = (N + block_size - 1) / block_size; // = 10 blocks per grid\n",
        "\n",
        "    somme<<<grid_size, block_size>>>(dev_a, dev_b);\n",
        "    somme<<<1, block_size>>>(dev_b, dev_c);\n",
        "    \n",
        "    cudaMemcpy(c, dev_c, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    \n",
        "    printf(\"\\nResults CPU = %1.0f\\nResults GPU = %4.0f\", sum, c[0]);\n",
        "\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results CPU = 10240\n",
            "Results GPU = 10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhKqQ_awCIJw"
      },
      "source": [
        "#### Program to calculate the sum of squares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zmrlViy2MvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b5cfc5-3cbc-4e4a-cc86-2ab3eadb969b"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 10000\n",
        "\n",
        "// Proposition 1\n",
        "// Improved version of the one from exercise 4, part b\n",
        "// It calculates the partial sum of a block, the rest is done on CPU\n",
        "// This is not the optimized method\n",
        "__global__ void square(int *a, float *c) {\n",
        "    __shared__ float temp[100]; //static allocation of shared memory\n",
        "\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    if(tid < N)\n",
        "        temp[threadIdx.x] = a[tid] * a[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        for (int i=0; i<blockDim.x; i++) {\n",
        "            c[blockIdx.x] += temp[i];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Proposition 2: Calculate the sum of an array using block reduction\n",
        "__global__ void sum(float *c, float *s) {\n",
        "    __shared__ float temp[100];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    temp[threadIdx.x] = c[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int step=1; step<blockDim.x; step*=2) {\n",
        "        if (tid % (2*step) == 0)\n",
        "            temp[tid] += temp[tid+step];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    s[0] = temp[0];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N];\n",
        "    int *dev_a;\n",
        "    float b, c[N], s[1];\n",
        "    float *dev_c, *dev_s;\n",
        "\n",
        "\n",
        "    cudaMalloc((void**)&dev_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N * sizeof(float));\n",
        "    cudaMalloc((void**)&dev_s, sizeof(float));\n",
        "\n",
        "    b = 0;\n",
        "    for (int i=0;i<N;i++) {\n",
        "        a[i] = i;\n",
        "        b += a[i] * a[i];\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    square<<<100,100>>>(dev_a, dev_c);\n",
        "\n",
        "    cudaMemcpy(c, dev_c, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    sum<<<1,100>>>(dev_c, dev_s);\n",
        "\n",
        "    cudaMemcpy(s, dev_s, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Proposition 1: Calculate the sum in CPU\n",
        "    float sum = 0;\n",
        "    for (int i=0; i<100; i++) {\n",
        "        sum += c[i];\n",
        "    }\n",
        "\n",
        "    printf(\"Resultat CPU = %1.0f\\nResultat GPU v1 = %1.0f\\nResultat GPU v2 = %1.0f\", b, sum, s[0]);\n",
        "\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_c);\n",
        "    cudaFree(dev_s);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultat CPU = 333283328000\n",
            "Resultat GPU v1 = 333283328000\n",
            "Resultat GPU v2 = 333283328000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GbraBAhNt6z"
      },
      "source": [
        "## ***Exercise 5: Matrix product***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TGbAWNsIp0C"
      },
      "source": [
        "* 3D data in CUDA: https://medium.com/@erangadulshan.14/1d-2d-and-3d-thread-allocation-for-loops-in-cuda-e0f908537a52\n",
        "* Matrix multiplication on CUDA : https://www.youtube.com/watch?v=XEOc4HCf_pQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KswZ7k4Pb32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbde374-4e3c-4d06-85d2-456421798536"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 8\n",
        "__global__ void product(int *a, int *b, float *c) {\n",
        "    int row = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "\n",
        "    float temp = 0;\n",
        "    if (row<N && col<N) {\n",
        "        for (int k=0; k<N; k++)\n",
        "            temp += a[row*N + k] * b[k*N + col];\n",
        "        c[row*N + col] = temp;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Matrices row-major\n",
        "// https://en.wikipedia.org/wiki/Row-_and_column-major_order\n",
        "int main () {\n",
        "    int a[N*N], b[N*N];\n",
        "    float c[N*N], c_gpu[N*N];\n",
        "\n",
        "    int *dev_a, *dev_b;\n",
        "    float *dev_c;\n",
        "\n",
        "    // Allocation en GPU\n",
        "    cudaMalloc((void**)&dev_a, N*N*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, N*N*sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, N*N*sizeof(float));\n",
        "\n",
        "    // Initialisation en CPU\n",
        "    for (int row=0; row<N; row++) {\n",
        "        for (int col=0; col<N; col++) {\n",
        "            a[row*N + col] = row+col;\n",
        "            b[row*N + col] = 2;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Produit de Matrices en CPU\n",
        "    for (int row=0; row<N; row++) {\n",
        "        for (int col=0; col<N; col++) {\n",
        "            int sum = 0;\n",
        "            for (int k=0; k<N; k++)\n",
        "                sum += a[row*N + k] * b[k*N + row];\n",
        "            c[row*N + col] = sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copy des valeurs sur GPU\n",
        "    cudaMemcpy(dev_a, a, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int BLOCK_SIZE = 4;\n",
        "    int GRID_SIZE = (N+BLOCK_SIZE-1)/BLOCK_SIZE;\n",
        "    dim3 grid(GRID_SIZE,GRID_SIZE);\n",
        "    dim3 block(BLOCK_SIZE,BLOCK_SIZE);\n",
        "    product<<<grid,block>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        "    cudaMemcpy(c_gpu, dev_c, N*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Resultat CPU:\\n\");\n",
        "    for (int row=0; row<N; row++) {\n",
        "        for (int col=0; col<N; col++) {\n",
        "            printf(\"%3.0f  \", c[row*N + col]);\n",
        "            if (col == N-1)\n",
        "                printf(\"\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"\\nResultat GPU:\\n\");\n",
        "    for (int row=0; row<N; row++) {\n",
        "        for (int col=0; col<N; col++) {\n",
        "            printf(\"%3.0f  \", c_gpu[row*N + col]);\n",
        "            if (col == N-1)\n",
        "                printf(\"\\n\");\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultat CPU:\n",
            " 56   56   56   56   56   56   56   56  \n",
            " 72   72   72   72   72   72   72   72  \n",
            " 88   88   88   88   88   88   88   88  \n",
            "104  104  104  104  104  104  104  104  \n",
            "120  120  120  120  120  120  120  120  \n",
            "136  136  136  136  136  136  136  136  \n",
            "152  152  152  152  152  152  152  152  \n",
            "168  168  168  168  168  168  168  168  \n",
            "\n",
            "Resultat GPU:\n",
            " 56   56   56   56   56   56   56   56  \n",
            " 72   72   72   72   72   72   72   72  \n",
            " 88   88   88   88   88   88   88   88  \n",
            "104  104  104  104  104  104  104  104  \n",
            "120  120  120  120  120  120  120  120  \n",
            "136  136  136  136  136  136  136  136  \n",
            "152  152  152  152  152  152  152  152  \n",
            "168  168  168  168  168  168  168  168  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pUs7Fwg62zF"
      },
      "source": [
        "## ***Exercise 6: Block Reduction - With indexing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaiDCoM0-aSL"
      },
      "source": [
        "> Supposing we have an array of length 32.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaNFyH9o-flJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8184bf-8e98-4c55-98fa-e405158055fc"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define SIZE 32\n",
        "\n",
        "float tree[2*SIZE];\n",
        "\n",
        "// Block reduction\n",
        "__global__ void add(float *t, int r) {\n",
        "    __shared__ float cache[SIZE*2];\n",
        "\n",
        "    cache[threadIdx.x] = t[threadIdx.x];\n",
        "    cache[threadIdx.x + SIZE] = t[threadIdx.x + SIZE];\n",
        "    __syncthreads();\n",
        "\n",
        "    while (r>1) {\n",
        "        int position = threadIdx.x + r;\n",
        "        if (position%2 == 0)\n",
        "            cache[position/2] = cache[position] + cache[position+1];\n",
        "        r /= 2;\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        t[1] = cache[1];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    // float tree[2*SIZE];\n",
        "    float *gpu_tree;\n",
        "    cudaMalloc((void **)&gpu_tree,SIZE*2*sizeof(float));\n",
        "\n",
        "    for(int i=SIZE;i<SIZE*2;i++)\n",
        "        tree[i] = float(2);\n",
        "    for(int i=0;i<SIZE*2;i++)\n",
        "        printf(\"%4.0f\",tree[i]);\n",
        "    printf(\"\\n\\n\");\n",
        "\n",
        "    cudaMemcpy(gpu_tree,tree,2*SIZE*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    \n",
        "    add<<<1,SIZE>>>(gpu_tree, SIZE);\n",
        "\n",
        "    cudaMemcpy(tree,gpu_tree,2*SIZE*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // The results are expected to be 2*32 = 64\n",
        "    for(int i=0;i<SIZE*2;i++)\n",
        "        printf(\"%4.0f\",tree[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(gpu_tree);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2\n",
            "\n",
            "   0  64   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7APTvqRK6sp"
      },
      "source": [
        "### But what happens if the array is long?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ios83y1TLqFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597699b1-e160-4ca6-a9f9-ce3bd4bae80d"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define SIZE 5120\n",
        "\n",
        "float tree[2*SIZE];\n",
        "\n",
        "__global__ void add(float *t, int r) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "\n",
        "    while (r>1) {\n",
        "        int position = tid + r;\n",
        "        if (position%2 == 0)\n",
        "            t[position/2] = t[position] + t[position+1];\n",
        "        r /= 2;\n",
        "        __syncthreads();\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    // float tree[2*SIZE];\n",
        "    float *gpu_tree;\n",
        "    cudaMalloc((void **)&gpu_tree,SIZE*2*sizeof(float));\n",
        "\n",
        "\n",
        "    for(int i=SIZE;i<SIZE*2;i++)\n",
        "        tree[i] = float(2);\n",
        "\n",
        "/*\n",
        "    for(int i=0;i<SIZE*2;i++)\n",
        "        printf(\"%4.0f\",tree[i]);\n",
        "    printf(\"\\n\\n\");\n",
        "*/\n",
        "    cudaMemcpy(gpu_tree,tree,2*SIZE*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    \n",
        "    int block_size = 512;\n",
        "    printf(\"Number of threads per block: %d\\n\", block_size);\n",
        "    int grid_size = (SIZE + block_size - 1)/block_size;\n",
        "    printf(\"Number of blocks: %d\\n\", grid_size);\n",
        "\n",
        "    add<<<grid_size,block_size>>>(gpu_tree, SIZE);\n",
        "\n",
        "    cudaMemcpy(tree,gpu_tree,2*SIZE*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\nThe first 16 cells:\\n\");\n",
        "    for (int i=0; i<16;i++)\n",
        "        printf(\"%6.0f\",tree[i]);\n",
        "\n",
        "    cudaFree(gpu_tree);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of threads per block: 512\n",
            "Number of blocks: 10\n",
            "\n",
            "The first 16 cells:\n",
            "     0  4096  6144  4096  4096  2048  2048  2048  2048  2048  1024  1024  1024  1024  1024  1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY8AGX7iSrN8"
      },
      "source": [
        "The result is supposed to be `2*5120 = 10240`. This one is wrong!\n",
        "\n",
        "We see that there are multiple blocks involved, which is different from the previous exercise.\n",
        "\n",
        "> In fact, `__syncthreads()` is limited insi\n",
        "de each block. We have to synchronize the workflow accros the grid.\n",
        "\n",
        "```\n",
        "__global__ void add(float *t, int r) {\n",
        "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "\n",
        "    while (r>1) {\n",
        "        int position = tid + r;\n",
        "        if (position%2 == 0)\n",
        "            t[position/2] = t[position] + t[position+1];\n",
        "        r /= 2;\n",
        "        __syncthreads();\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "Indeed the work between the blocks is not synchronized. \n",
        "\n",
        "For example, `t[2048]` and `t[4096]` belong different blocks. We calculate `t[2048] = t[4096] + t[4097]`, and on the next step `t[1024] = t[2048] + t[2049]` √† l'√©tape suivant. This \"order\" is not always maintained in parallel environment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5RHdy3rRyyn"
      },
      "source": [
        "> **Improved version**\n",
        "\n",
        "Frankly, I didn't know why this version is not correct..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3qFTEZrWkKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4332882c-4e38-416b-bdb7-678595cc3f11"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#define SIZE 1024*12\n",
        "\n",
        "float tree[2*SIZE];\n",
        "\n",
        "// Noyau GPU. On ajoute \"num_bloc\" pour calculer la position \n",
        "__global__ void add(float *t, int r, int num_bloc) {\n",
        "    while (r>1) {\n",
        "        int position = threadIdx.x + r + num_bloc*1024; // On abanddonne le \"tid\"\n",
        "        if (position%2 == 0)\n",
        "            t[position/2] = t[position] + t[position+1];\n",
        "        r /= 2;\n",
        "        __syncthreads();\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    // float tree[2*SIZE];\n",
        "    float *gpu_tree;\n",
        "    cudaMalloc((void **)&gpu_tree,SIZE*2*sizeof(float));\n",
        "\n",
        "    float somme_cpu = 0;\n",
        "    for(int i=SIZE;i<SIZE*2;i++) {\n",
        "        tree[i] = float(2);\n",
        "        somme_cpu += tree[i];\n",
        "    }\n",
        "    cudaMemcpy(gpu_tree,tree,2*SIZE*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    \n",
        "    int block_size = 1024;\n",
        "    printf(\"Number of threads per block: %d\\n\", block_size);\n",
        "    int num_bloc = (SIZE + block_size - 1)/block_size;\n",
        "    printf(\"Number of blocks %d\\n\", num_bloc);\n",
        "\n",
        "    if (num_bloc == 1) {\n",
        "        add<<<num_bloc,block_size>>>(gpu_tree, SIZE, 0);\n",
        "    }\n",
        "    else {\n",
        "        int t = SIZE;\n",
        "        while (t>1) {\n",
        "            for (int i=0; i<num_bloc; i++)\n",
        "                add<<<1, block_size>>>(gpu_tree, SIZE, i);\n",
        "            t = t/2;      \n",
        "        }\n",
        "    }\n",
        "    cudaMemcpy(tree,gpu_tree,2*SIZE*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Results CPU: %6.0f\\n\", somme_cpu);\n",
        "    printf(\"Results GPU: %6.0f\\n\", tree[2]);\n",
        "    for (int i=0; i<20;i++)\n",
        "        printf(\"%6.0f\",tree[2]);\n",
        "\n",
        "    cudaFree(gpu_tree);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de threads par block: 1024\n",
            "Nombre de blocks: 12\n",
            "Somme CPU:  24576\n",
            "Somme GPU:  16384\n",
            " 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384 16384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lCtg-VC62x7"
      },
      "source": [
        "##***Exercise 7: Matrix product***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "172zHo4lakWN"
      },
      "source": [
        "Supposing we need to calculate the product of two matrix:\n",
        "\n",
        "|   |  |  |\n",
        "| --- | --- | --- |\n",
        "| a0  | a1 | a2 |\n",
        "| a3  | a4 | a5 |\n",
        "| a6  | a7 | a8 |\n",
        "\n",
        "and\n",
        "\n",
        "|   |  |  |\n",
        "| --- | --- | --- |\n",
        "| b0  | b1 | b2 |\n",
        "| b3  | b4 | b5 |\n",
        "| b6  | b7 | b8 |\n",
        "\n",
        "**For example**, we can allocate the shared memory as follows (with `3x3` matrix):\n",
        "\n",
        "|         \t| t0   \t| t1   \t| t2   \t| t3   \t| t4   \t| t5   \t| t6   \t| t7   \t| t8   \t|\n",
        "|---------\t|------\t|------\t|------\t|------\t|------\t|------\t|------\t|------\t|------\t|\n",
        "| **block 0** \t| a0b0 \t| a0b1 \t| a0b2 \t| a1b3 \t| a1b4 \t| a1b5 \t| a2b6 \t| a2b7 \t| a2b8 \t|\n",
        "| **block 1** \t| a3b0 \t| a3b1 \t| a3b2 \t| a4b3 \t| a4b4 \t| a4b5 \t| a5b6 \t| a5b7 \t| a5b8 \t|\n",
        "| **block 2** \t| a6b0 \t| a6b1 \t| a8b2 \t| a7b3 \t| a7b4 \t| a7b5 \t| a8b6 \t| a8b7 \t| a8a8 \t|\n",
        "\n",
        "Then, we calculate  `t0   t1   t2`\n",
        "```\n",
        "t0 = t0 + t3 + t6\n",
        "t1 = t1 + t4 + t7\n",
        "t2 = t2 + t5 + t8\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfJ31kdi9ylq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7432e0c-d9d3-4154-90e8-b7127d71f6b1"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define row 3\n",
        "#define col 3\n",
        "\n",
        "__global__ void produit(int *a, int *b, float *c) {\n",
        "    __shared__ float temp[row*col];\n",
        "    int num_bloc = blockIdx.x;\n",
        "\n",
        "    // Coefficients\n",
        "    int tid = threadIdx.x;\n",
        "    int b_coeff = threadIdx.x; // Coefficient de \"b\"\n",
        "    int a_coeff = (threadIdx.x/col) + num_bloc*col; // Coefficient de \"a\"\n",
        "\n",
        "    // Partial product\n",
        "    temp[tid] = a[a_coeff] * b[b_coeff];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Sum of partial product in \"temp\"\n",
        "    if (tid < col) {\n",
        "        for (int i=1; i<col; i++) // Mdr il faut accumuler la somme a partir de i=1, sinon temp[0] += temp[0] + temp[3] + temp[6]\n",
        "            temp[tid] += temp[tid + i*col]; // Accumulation de somme\n",
        "        __syncthreads();\n",
        "        c[tid + num_bloc*col] = temp[tid]; // Sauvegarder le resultat a une case\n",
        "    }\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    int a[row*col], b[row*col];\n",
        "    float  c_cpu[row*col], c_gpu[row*col];\n",
        "    int *a_dev, *b_dev;\n",
        "    float *c_dev;\n",
        "\n",
        "    cudaMalloc((void **)&a_dev,row*col*sizeof(int));\n",
        "    cudaMalloc((void **)&b_dev,row*col*sizeof(int));\n",
        "    cudaMalloc((void **)&c_dev,row*col*sizeof(float));\n",
        "\n",
        "    // Initialization\n",
        "    for (int i=0; i<row; i++) {\n",
        "        for (int j=0; j<col; j++) {\n",
        "            a[i*row + j] = i+j;\n",
        "            b[i*row + j] = 2;\n",
        "        }\n",
        "    }\n",
        "/*\n",
        "    for (int row=0; row<N; row++) {\n",
        "        for (int col=0; col<N; col++) {\n",
        "            int sum = 0;\n",
        "            for (int k=0; k<N; k++)\n",
        "                sum += a[row*N + k] * b[k*N + row];\n",
        "            c[row*N + col] = sum;\n",
        "        }\n",
        "    }\n",
        "*/\n",
        "    // CPU sum\n",
        "    for (int i=0; i<row; i++) {\n",
        "        for (int j=0; j<col; j++) {\n",
        "            int temp = 0;\n",
        "            for (int k=0; k<col; k++) {\n",
        "                temp += a[i*row + k] * b[k*col + i];\n",
        "            }\n",
        "            c_cpu[i*row + j] = temp;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(a_dev,a,row*col*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(b_dev,b,row*col*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "    int block_size = col*row;\n",
        "    int grid_size = row;\n",
        "    produit<<<grid_size, block_size>>>(a_dev, b_dev, c_dev);\n",
        "\n",
        "    cudaMemcpy(c_gpu,c_dev,row*col*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Resultat CPU:\\n\");\n",
        "    for (int i=0;i<row; i++) {\n",
        "        for (int j=0;j<col; j++) {\n",
        "            printf(\"%5.0f\",c_cpu[i*row + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\nResultat GPU:\\n\");\n",
        "    for (int i=0;i<row; i++) {\n",
        "        for (int j=0;j<col; j++) {\n",
        "            printf(\"%5.0f\",c_gpu[i*row + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(a_dev);\n",
        "    cudaFree(b_dev);\n",
        "    cudaFree(c_dev);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultat CPU:\n",
            "    6    6    6\n",
            "   12   12   12\n",
            "   18   18   18\n",
            "\n",
            "Resultat GPU:\n",
            "    6    6    6\n",
            "   12   12   12\n",
            "   18   18   18\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opXVS7QUCSU_"
      },
      "source": [
        "##***Exercise 8: Code analysis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdI8Chu_CeUH"
      },
      "source": [
        "> Look at the code below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9dlYrvCpml"
      },
      "source": [
        "```\n",
        "1 #define SIZE 16384\n",
        "float data[SIZE];\n",
        "...\n",
        "__global__ void do( float* a, float *b)\n",
        "{\n",
        "    int localisation = blockIdx.y * gridDim.x + blockIdx.x;\n",
        "    int thread_reference = localisation * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x;\n",
        "    ...\n",
        "    /* Do something on a[thread_reference] and b[thread_reference] */\n",
        "    ...\n",
        "}\n",
        "    ...\n",
        "    dim3 dimBlock(16,16);\n",
        "    dim3 dimGrid(8,8);\n",
        "    do<<<dimGrid, dimBlock>>>(ref_input, ref_output);\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOiC4qv7EaDE"
      },
      "source": [
        "###a. In the program, how the matrix is represented by a one-dimensional array? How is it possible? \n",
        "\n",
        "> CUDA Thread Indexing Cheat Sheet: https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKziMMZvU3by"
      },
      "source": [
        "###b. How many threads are going to be executed ?\n",
        "```\n",
        "dim3 dimBlock(16,16);\n",
        "dim3 dimGrid(8,8);\n",
        "```\n",
        "* Number of blocks in the grid: `8x8 = 64`\n",
        "* In each block, there are `16x16 = 256` threads\n",
        "* In total, there are`64x256 = 16384` threads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOjOwy76fSAU"
      },
      "source": [
        "##***Exercise 9: Write a kernel***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ-DcvmAh8Ng"
      },
      "source": [
        "> Write a kernel to verify if a 2D array is Sudoku matrix or not\n",
        "\n",
        "We test our program on `16x16` matrix, therefore a single block with shared memory is enough.\n",
        "\n",
        "* Shared memory `temp` is for saving the input array; \n",
        "\n",
        "* Each thread runs on a `tid` cell of the input array `a` and determines: If there is a collision `temp[tid]` in hortizontal and vertical direction, along with collision in a square `4x4`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBiLSFr8tB78"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#define N 16\n",
        "__global__ void check(int *a, int *s) {\n",
        "    int tid = threadIdx.y * blockDim.x + threadIdx.x; // A single block with shared memory\n",
        "    __shared__ int temp[N*N];\n",
        "\n",
        "    // Copy input value into shared memory\n",
        "    temp[tid] = a[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Horizontal : Compare the cell with neighbor values \"on the left\"\n",
        "    for (int i=0; i<threadIdx.x; i++) {\n",
        "        if (temp[threadIdx.y*blockDim.x + i] == temp[tid]) {\n",
        "            s += 1;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    // Vetical : Compare the cell with neighbor values \"above\"\n",
        "    for (int j=0; j < threadIdx.y; j++) {\n",
        "        if (temp[threadIdx.x*blockDim.y + j] == temp[tid]) {\n",
        "            s[0] += 1;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Square\n",
        "    int square_y = threadIdx.y / 4; // Square coordinates on dimension y\n",
        "    int square_x = threadIdx.x / 4; // Square coordinates on dimension x\n",
        "    // int tid_square = 4 * blockDim.x * square_y + 4*square_x; // tid of the first cell in the square\n",
        "\n",
        "    // Comparison inside the sqaure\n",
        "    for (int i=0; i<4; i++) { // Row of square\n",
        "        for (int j=0; j<4; j++) { // Column of square\n",
        "            int tid_cell = 4*blockDim.x*square_y + i*blockDim.x + 4*square_x + j; // tid of the cell\n",
        "            if (tid_cell != tid) { // Skip the current case\n",
        "                if (temp[tid_cell] == temp[tid]) {\n",
        "                    s += 1;\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    int a[N*N];\n",
        "    int s[1];\n",
        "    int *a_dev, *s_dev;\n",
        "\n",
        "    s[0] = 0;\n",
        "    cudaMalloc((void **)&a_dev,N*N*sizeof(int));\n",
        "    cudaMalloc((void **)&s_dev,sizeof(int));\n",
        "\n",
        "    // Initialisation\n",
        "    for (int i=0; i<N*N; i++)\n",
        "        a[i] = i;\n",
        "    \n",
        "    cudaMemcpy(a_dev,a,N*N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(s_dev,s,sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "    int block_size = N*N;\n",
        "    int grid_size = 1;\n",
        "    check<<<grid_size, block_size>>>(a_dev, s_dev);\n",
        "\n",
        "    cudaMemcpy(s,s_dev,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (s > 0)\n",
        "        printf(\"This is a Sudoku table.\\n\");\n",
        "    else\n",
        "        printf(\"\\nThis is not a Sudoku table.\\n\");\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS3ziyH2a3UI"
      },
      "source": [
        "## ***Exercise 10: Memory Accessing Improvements***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLvV4Uh9bVZZ"
      },
      "source": [
        "__global do(float A[N], float B[N])\n",
        "{\n",
        "    block_number = blockIdx.y * gridDim.x + blockIdx.x;\n",
        "    thread_number = block_number * blockDim.y * blockDim.x + threadIdx.x * blockDim.y + threadIdx.y;\n",
        "    resultat_intermediare = calcul(A[thread_number])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoPark_cbc9D"
      },
      "source": [
        "dim3 block_size;\n",
        "block_size.x = 32;\n",
        "block_size.y = 32;\n",
        "dim3 grid_size;\n",
        "grid_size.x = 10;\n",
        "grid_size.y = 10;\n",
        "do<<<grid_size,block_size>>>(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGlj1xJbe3L"
      },
      "source": [
        "The grid contains `10x10` blocks, in each block there are` 32x32` threads.\n",
        "\n",
        "We see that thread access is not really efficient since it is not **continuous**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHk1epEtb_rO"
      },
      "source": [
        "###Improvements\n",
        "\n",
        "```\n",
        "block_number = blockIdx.y * gridDim.x + blockIdx.x;\n",
        "thread_number = block_number * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x;\n",
        "```"
      ]
    }
  ]
}